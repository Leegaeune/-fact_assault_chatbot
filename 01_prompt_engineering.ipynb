{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6380ef6e",
   "metadata": {},
   "source": [
    "# 프롬포트 엔지니어링 with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518e241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.102.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from openai) (4.10.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.102.0-py3-none-any.whl (812 kB)\n",
      "   ---------------------------------------- 0.0/812.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 812.0/812.0 kB 34.4 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 27.3 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [pydantic-core]\n",
      "   ----------------- ---------------------- 3/7 [distro]\n",
      "   ----------------- ---------------------- 3/7 [distro]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------- ----------- 5/7 [pydantic]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [openai]\n",
      "   ---------------------------------------- 7/7 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.10.0 openai-1.102.0 pydantic-2.11.7 pydantic-core-2.33.2 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599d52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc0612",
   "metadata": {},
   "source": [
    "### Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7693149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":[\n",
    "                {\n",
    "                    \"type\":\"text\",\n",
    "                    \"text\":\"넌 욕쟁이 옆집 아주머니 같은 챗봇이야\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":[\n",
    "                    {\n",
    "                        \"type\":\"text\",\n",
    "                        \"text\":\"비를 많이 맞은 날 점심으로 뭘 먹으면 좋을까?\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"text\"  \n",
    "    },\n",
    "    temperature=1.0,       # 대답 창의성\n",
    "    max_tokens=2048,        # 응답 최대 토큰 수     \n",
    "    top_p=1,             # 사용할 상위 누적 확률\n",
    "    frequency_penalty=0,     # 토큰 사용 빈도수에 대한 불이익\n",
    "    presence_penalty=0,      # 토큰 재사용에 대한 불이익\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2298e51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'비를 많이 맞아서 몸이 좀 추울 거야. 이런 날엔 따뜻한 국물이 최고지! 칼국수나 된장찌개 어때? 뜨끈한 국물이랑 밥이랑 같이 먹으면 금방 기운 차릴 거야. 아니면 닭백숙도 좋고! 몸이 따뜻해질 거야. 든든하게 먹고 건강 챙겨야 해!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b5e4cf",
   "metadata": {},
   "source": [
    "#### 기사 제목 교정\n",
    "- 프랑스 AFP시스템 최초 적용\n",
    "- 기자들이 숭고한 제목에서 맞춤법, 의미, 어조 등의 교정 작업 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b67e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_title(query, temperature=0.3):\n",
    "    client = OpenAI()\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "    당신은 편집장입니다. 기자들이 송고한 기사 제목을 교정하세요.\n",
    "\n",
    "    ### 지시사항 ###\n",
    "    - 기사의 제목이 명확하고 주제와 잘 맞도록 수정할 것\n",
    "    - 독자의 관심을 끌 수 있도록 간결하고 임팩트 있는 표현을 사용할 것\n",
    "    - 비속어, 은어 등은 제거하고 의미가 유지되도록 교정할 것\n",
    "\n",
    "    ### 출력 형식 ###\n",
    "    - 원래 제목: [기사의 원래 제목]\n",
    "    - 교정 제목:\n",
    "        [기사의 교정된 제목]\n",
    "        [기사의 교정된 제목]\n",
    "        [기사의 교정된 제목]\n",
    "\n",
    "    ### 예시 ###\n",
    "    - 원래 제목: \"어제 서울에 큼불이 나서 수백명이 대피했다.\"\n",
    "    - 교정 제목:\n",
    "        \"서울 대형 화재, 수백명 대피!\"\n",
    "        \"서울서 화재, 수백명 대피해...\"\n",
    "        \"수백명 대피한 서울 화재\"\n",
    "\"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    다음 제목을 교정해 주세요.\n",
    "    제목: {query}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": system_instruction\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_message\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        temperature=temperature,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=1,\n",
    "        presence_penalty=1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_title('비 오는 날 개꿀잼 라이오 사연이 나옵니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bdf890",
   "metadata": {},
   "source": [
    "# 영단어징 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_title(query, temperature=0.3):\n",
    "    client = OpenAI()\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "    당신은 편집장입니다. 기자들이 송고한 기사 제목을 교정하세요.\n",
    "\n",
    "    ### 지시사항 ###\n",
    "    - 기사의 제목이 명확하고 주제와 잘 맞도록 수정할 것\n",
    "    - 독자의 관심을 끌 수 있도록 간결하고 임팩트 있는 표현을 사용할 것\n",
    "    - 비속어, 은어 등은 제거하고 의미가 유지되도록 교정할 것\n",
    "\n",
    "    ### 출력 형식 ###\n",
    "    - 원래 제목: [기사의 원래 제목]\n",
    "    - 교정 제목:\n",
    "        [기사의 교정된 제목]\n",
    "        [기사의 교정된 제목]\n",
    "        [기사의 교정된 제목]\n",
    "\n",
    "    ### 예시 ###\n",
    "    - 원래 제목: \"어제 서울에 큼불이 나서 수백명이 대피했다.\"\n",
    "    - 교정 제목:\n",
    "        \"서울 대형 화재, 수백명 대피!\"\n",
    "        \"서울서 화재, 수백명 대피해...\"\n",
    "        \"수백명 대피한 서울 화재\"\n",
    "\"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    다음 제목을 교정해 주세요.\n",
    "    제목: {query}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": system_instruction\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_message\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"json_object\"       # json 객체로 반환\n",
    "        },\n",
    "        temperature=temperature,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=1,\n",
    "        presence_penalty=1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "ressult = correct_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a317e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf20e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "result=print(json.loads(ressult))\n",
    "\n",
    "for word in result['json_list']:\n",
    "    print(word_dict['단어'])\n",
    "    print(word_dict['뜻'])\n",
    "\n",
    "    for\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dba0ab",
   "metadata": {},
   "source": [
    "### ReAct 기법\n",
    "- Reason & Action 기법 : 현재 상황에 대한 통찰 이후 다음 행동에 대한 작성을 유도하는 기법\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e7a70",
   "metadata": {},
   "source": [
    "### 연애코치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5edc405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dating_coach(query, temperature=0.3):\n",
    "    client = OpenAI()   # () 안에 api_key=OPENAI_API_KEY 넣어도 되지만 안넣어도 load_dotenv()로 자동으로 환경변수에서 불러옴\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "    어떤 상황에서든 최고의 논리적/감성적 관점을 적용하는 연애 코치로서 사용자의 고민을 해결해 주세요.\n",
    "\n",
    "    ### 출력 형식 ###\n",
    "    1. 상황 분석:\n",
    "\n",
    "    2. 행동 계획:\n",
    "\n",
    "    3. 실행:\n",
    "\"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    사용자의 현재 상황: {query}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": system_instruction\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_message\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        temperature=temperature,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=1,\n",
    "        presence_penalty=1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff63e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "244b65d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 상황 분석:\n",
      "   - 생일은 많은 사람들에게 중요한 날이며, 특히 가까운 관계에서는 상대방이 기억해주길 기대합니다.\n",
      "   - 남자친구가 반복적으로 이런 중요한 기념일을 잊는다면, 이는 당신의 감정을 충분히 고려하지 않는다는 느낌을 줄 수 있습니다.\n",
      "   - 그러나 헤어지기 전에 문제의 원인을 파악하고 해결할 방법을 모색하는 것이 중요합니다.\n",
      "\n",
      "2. 행동 계획:\n",
      "   - 먼저 자신의 감정을 솔직하게 표현하세요. 그에게 생일이 왜 중요한지 설명하고, 그의 무관심으로 인해 어떻게 느끼는지를 이야기하세요.\n",
      "   - 대화를 통해 그의 입장을 들어보세요. 그는 단순히 건망증이 심한 것인지, 아니면 다른 이유가 있는지 알아보세요.\n",
      "   - 함께 해결책을 찾아보세요. 예를 들어, 캘린더에 알림 설정하기 등 실질적인 방안을 제안할 수 있습니다.\n",
      "\n",
      "3. 실행:\n",
      "   - 편안한 분위기에서 대화를 시작하세요. 비난하는 대신 이해하려고 노력하며 서로의 관점을 공유하세요.\n",
      "   - 만약 그가 진정으로 사과하고 개선하겠다고 약속한다면 시간을 주고 지켜봐 주세요.\n",
      "   - 하지만 이러한 노력이 반복적으로 실패하거나 변화가 없다면 더 큰 결단도 고려해야 할 것입니다.\n",
      "\n",
      "결국 관계는 상호 존중과 이해를 바탕으로 합니다. 두 사람이 함께 성장할 수 있는 방향으로 나아갈 수 있도록 최선을 다해 보세요!\n"
     ]
    }
   ],
   "source": [
    "problem =\"남자친구가 제 생일을 까먹었어요. 매번 이런식이에요. 헤어질까요?\"\n",
    "print(dating_coach(problem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a483f62b",
   "metadata": {},
   "source": [
    "#### 냉장고를 부탁해\n",
    "- quary: 냉장고에 있는 재료 목록\n",
    "- return: quary로 받은 재료를 활용한 레시피 작성\n",
    "- [hint]현재 상황에 대한 분석/파악 > 행동 계획 > 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b35f4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_my_fridge(query, temperature=0.3):\n",
    "    client = OpenAI()   # () 안에 api_key=OPENAI_API_KEY 넣어도 되지만 안넣어도 load_dotenv()로 자동으로 환경변수에서 불러옴\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "    냉장고에 있는 재료로 할 수 있는 요리를 레시피로 만들어 주세요.\n",
    "\n",
    "    ### 출력 형식 ###\n",
    "    1. 상황 분석:\n",
    "\n",
    "    2. 행동 계획:\n",
    "\n",
    "    3. 실행:\n",
    "\"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    사용자의 현재 상황: {query}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": system_instruction\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_message\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        temperature=temperature,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=1,\n",
    "        presence_penalty=1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7304df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 상황 분석:\n",
      "   - 사용자는 현재 냉장고에 토마토, 당근, 양파, 감자를 보유하고 있습니다.\n",
      "   - 이 재료들은 모두 신선한 채소로 다양한 요리에 활용할 수 있으며, 특히 스프나 스튜와 같은 요리에 적합합니다.\n",
      "\n",
      "2. 행동 계획:\n",
      "   - 위의 재료들을 이용하여 간단하면서도 맛있는 \"채소 스튜\"를 만들겠습니다.\n",
      "   - 필요한 추가 기본 재료: 올리브 오일(또는 식용유), 소금, 후추, 물 또는 야채 육수\n",
      "   - 조리 시간은 약 30-40분으로 예상됩니다.\n",
      "\n",
      "3. 실행:\n",
      "\n",
      "**재료:**\n",
      "- 토마토 2개\n",
      "- 당근 1개\n",
      "- 양파 1개\n",
      "- 감자 2개\n",
      "- 올리브 오일 또는 식용유 2큰술\n",
      "- 소금과 후추 (기호에 따라)\n",
      "- 물 또는 야채 육수 약 4컵\n",
      "\n",
      "**조리 방법:**\n",
      "\n",
      "1. **준비 작업:** \n",
      "    - 모든 채소를 깨끗이 씻습니다.\n",
      "    - 토마토는 껍질을 벗기고 깍둑썰기 합니다.\n",
      "    - 당근은 얇게 슬라이스하거나 작은 크기로 자릅니다.\n",
      "    - 양파는 다지거나 얇게 썹니다.\n",
      "    - 감자는 껍질을 벗긴 후 한입 크기로 잘라줍니다.\n",
      "\n",
      "2. **볶기:**\n",
      "    - 큰 냄비에 올리브 오일을 두르고 중불에서 가열합니다.\n",
      "    - 양파를 넣고 투명해질 때까지 볶습니다 (약 3~5분).\n",
      "  \n",
      "3. **조합하기:**\n",
      "    - 준비된 당근과 감자를 냄비에 추가하고 몇 분간 더 볶아줍니다.\n",
      "  \n",
      "4. **스튜 끓이기:**\n",
      "    - 깍둑썬 토마토와 물(또는 야채 육수)을 냄비에 붓습니다.\n",
      "    - 소금과 후추로 간을 맞춥니다.\n",
      "\n",
      "5. **끓이고 졸이기:**\n",
      "     – 혼합물을 끓인 뒤 불을 줄여서 뚜껑을 덮고 약한 불에서 약 20~25분 동안 끓입니다. 이때 채소가 부드러워질 때까지 익힙니다.\n",
      "\n",
      "6. **완성 및 서빙:**\n",
      "     – 필요시 간을 다시 확인하고 부족하면 추가 조절합니다.\n",
      "     – 그릇에 담아 따뜻하게 서빙하세요.\n",
      "\n",
      "맛있게 드세요!\n"
     ]
    }
   ],
   "source": [
    "food =\"토마토, 당근, 양파, 감자\"\n",
    "print(finish_my_fridge(food))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821e62f",
   "metadata": {},
   "source": [
    "##### 면접 질문 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aaef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인성 면접/기술면접으로 나누어 각각 예상질문과 답변을 생성해 반환\n",
    "def job_interview(query, temperature=0.3):\n",
    "    client = OpenAI()   # () 안에 api_key=OPENAI_API_KEY 넣어도 되지만 안넣어도 load_dotenv()로 자동으로 환경변수에서 불러옴\n",
    "\n",
    "    system_instruction = \"\"\"\n",
    "    \n",
    "\n",
    "    ### 출력 형식 ###\n",
    "    1. 상황 분석:\n",
    "\n",
    "    2. 행동 계획:\n",
    "\n",
    "    3. 실행:\n",
    "\"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    사용자의 현재 상황: {query}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": system_instruction\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_message\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        temperature=temperature,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=1,\n",
    "        presence_penalty=1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e31f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_interview_json(query, temperature=0.3):\n",
    "    # hard skill(기술질문), soft skill(태도/생각 질문)을 나누어 각각 예상질문과 답변을 json형식으로 반환\n",
    "    # query = 채용공고\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
