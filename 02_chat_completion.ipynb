{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b76e692",
   "metadata": {},
   "source": [
    "# Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48581d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2cd4f7",
   "metadata": {},
   "source": [
    "### chat completion: massages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response =client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\",\"content\":\"너는 친절하고 상세한 설명을 잘하는 챗봇이야\"}\n",
    "        {\"role\":\"user\",\"content\":\"안녕, 난 가은이야\"}\n",
    "        {\"role\":\"assistant\",\"content\":\"안녕하세요. 가은님, 무엇을 도와드릴까요?\"}\n",
    "        {\"role\":\"user\",\"content\":\"안녕, 내 이름이 뭐라고?\"}\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949903d",
   "metadata": {},
   "source": [
    "### stream 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939ecec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "stream_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "\n",
    "        {\"role\":\"user\",\"content\":\"stream 테스트하게 아주 긴 응답 메시지를 보내줘\"},\n",
    "\n",
    "    ],\n",
    "    stream=True,\n",
    "    # temperature=1,\n",
    "    # max_tokens=4096,\n",
    "    # top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "880a8e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답 완료\n"
     ]
    }
   ],
   "source": [
    "for chunk in stream_response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "\n",
    "    if content is not None:\n",
    "        print(content, end='')\n",
    "\n",
    "print(\"응답 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389861a",
   "metadata": {},
   "source": [
    "### Token counting\n",
    "- 한번의 프롬포트 입출력 토큰과 서비스 호출 빈도를 고려해 서비스 제공 비용을 산정할 수 있음\n",
    "- 비용 =((입력 토큰수*입력 단가) + (출력 토큰 수 * 출력 단가) * 월 서비스 호출 수\n",
    "- 온라인 테스트\n",
    "- 파이썬 테스트 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c88dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from tiktoken) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 884.3/884.3 kB 38.9 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32ea22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "430\n",
      "430\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "gpt35 = tiktoken.encoding_for_model(\"gpt-3.5\")\n",
    "gpt4o=tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "gpt41=tiktoken.encoding_for_model(\"gpt-4.1\")\n",
    "\n",
    "text =\"\"\"마이크로소프트(MS)가 드디어 자체 개발 대형언어모델(LLM) '마이(MAI)'를 공개했다. 이를 통해 기업용이 아닌, 개인용 인공지능(AI) 비서를 구축하겠다는 뜻을 강조했다. 동시에 이는 오픈AI 기술 의존도를 줄이려는 의도이기도 하다.\n",
    "\n",
    "MS는 28일(현지시간) 홈페이지를 통해 음성 생성 모델 '마이-보이스-1(MAI-Voice-1)'과 LLM '마이-1-프리뷰(MAI-1-preview)'를 선보였다.\n",
    "\n",
    "보이스 모델은 코파일럿 서비스 중 뉴스 요약을 들려주거나 팟캐스트를 제작하는 기능 등에 이미 적용됐다. 코파일럿 랩스에서도 체험할 수 있다. \"음성은 AI 동반자를 위한 미래형 인터페이스\"라고 설명했다.\n",
    "\n",
    "마이-1-프리뷰는 말 그대로 현재 미리보기 테스트 중이다. 우선, 사용자 선호도를 평가하는 LM아레나에 업로드됐다. 또 개발자들이 체험할 수 있는 API 대기자 명단을 공개했다. 몇주 내로 코파일럿의 특정 사례에도 적용, 사용자 피드백을 통해 개선할 계획이다.\n",
    "\n",
    "MS는 마이 파운데이션 모델을 엔드 투 엔드, 즉 처음부터 끝까지 자체 학습했다고 강조했다. \n",
    "\n",
    "또 약 1만5000개의 엔비디아 'H100' GPU에서 사전 훈련과 사후 훈련을 거친 '전문가 혼합(MoE)' 모델이라고 밝혔다. \"사용자의 지시를 따르고 일상적인 질문에 유용한 답변을 제공하는 데 특화됐다\"라고 소개했다.\n",
    "\n",
    "하지만, 더 이상 자세한 내용은 공개하지 않았으며, 앞으로 점차 발표할 것이라고 덧붙였다.\n",
    "\n",
    "\n",
    "\n",
    "출처 : AI타임스(https://www.aitimes.com)\n",
    "\"\"\"\n",
    "print(len(gpt35.encode(text)))\n",
    "print(len(gpt4o.encode(text)))\n",
    "print(len(gpt41.encode(text)))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
